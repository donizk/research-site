---
title: "Post_Feasibility"
description: "discussion on my senior project design and its feasiblity"
date: 2022-04-06T19:58:50-04:00
draft: false
tags: [data-analysis, economics, statistics]
---

### Discussion on the Feasiblity of my Senior Project Idea

For my project, there isn't really much to hardware equipment needed to run this project besides having a computer. But having the computer of the right specifications is what will really ensure whether or not a tool will run smoothly on a machine. Computer specifications vary from program to program, but generally, the machine I decide to run the code for my project would need to be a x64 machine and have anywhere between 1-16 GB of RAM. The computer specifications for running my project will also be determined by the the type and volume of data I want to tackle.

For my project, there is quite a wide breadth of tools I have at my disposal, each with similar use-cases and/or specialized uses.

The full listing of tools I am considering on using includes:

- Stata
- R & R-Studio (using packages: ggplot2, dplyr, tidyr, plotly)
- Python (using packages: pandas, SciPy, NumPy, Matplotlib, SciKit-Learn)
- RapidMiner
- Hadoop
- Spark
- Tableau
- KNIME
- SAS
- SPSS
- SQL

The main differences between all of these tools for the volume of data that each is equipped to handle and the types of analysis that can be performed. Some of these tools are purely/primarily used for constructing visualizations like is the case for Tableau, while other tools are specifically made to only handle larger data sets like Hadoop and Spark.

With my Computer Science classes, I have been able to learn a wide variety of languages, including Java, Python, C, and R, and different ways to apply these languages. I have also just generally learned what it's like to plan, execute, and deliver a completed project, whether it be a data analysis report or a tool I built for some use-case. With the current idea I have for my project, I think I will be working more specifically with data analysis instead of software development, so I expect my deliverable to be more like a report that features code blocks that are run to execute different calculations or create different visualizations. Given that I want to focus on analyzing data, finding patterns in that data, and drawing conclusions from that data, I will need to employ tools that specific to those functions. Of the tools in my current arsenal, from a Computer Science standpoint, I know and have experience with leveraging R for data analysis, and I have general Python knowledge that I have gained in my intro course and have since worked on tools based on this knowledge.

I also like to consider myself a quick learner, as I am consistently having to learn new things as I am getting older and my responsiblities are increasing. I never let any challenge deter me, and a challenge is actually what fuels and gets me excited to tackle any given task. I am also very quick at learning new technical skills, as this is something I have probably had to do since my freshman year of high school. I get kind of restless when I don't understand a piece of code or how I should execute something, and I don't stop until I find an answer or working solution to my problem. I also feel that my Economics, and more specifically, my statistical knowledge, will be extremely helpful for me in terms of having a leg up in understanding how to measure correlation between two variables and all of the statistical calculations that show that.

At this current moment, I am unsure if my project will require the use of existing or new data; I think generally that will be a decision I have to make. I would want to look into finding multiple data sets that would look to answer the question of how poverty impacts what level of education a person will achieve and how it will impact their access to education, along with other socioeconomic factors. Given that this rates of education and poverty are two subjects of interest to me in this analysis, I would have to find data sets, then, that include data points on those things. I will look to obtain this data from various sources including Google's Dataset Search, Kaggle, Data.gov, The World Bank, and Data Hub. Having done a cursory search on each of these sites, I have found that I can access a large breadth of different data sets that deal with poverty and education either directly or indirectly through related indicators. I know that I will definitely need more than one data set, in order to perform effective analysis, and additionally, I would need to make sure I have multiple data points for each thing I want to test.

I anticipate that this project will take maybe 1-2 months to complete, with a month left to finalize my analysis and report, and to address any issues I have with my results. I think that finding and acquiring data sets for my project will take a week or two, maybe even 3, just to ensure that the data sets I select cover the breadth of the topics I want to study. After acquiring the data I would like to perform analysis on, I would need to start actually interacting with data with my selected tool(s), through manipulation, developing visualizations, and get statistics about the data. This could take anywhere from a couple of weeks to a month, since I would need to deal with a large amount of data, as well as, giving myself run for running into errors that I may need to troubleshoot along the way. That would then leave me with a little more than a month to tackle summarizing my findings and writing my report, while also ensuring to include economic analysis and models into my report to help bolster my findings and the analysis of the data. Of course, this is all theoretical and depends on whether or not this is something that my professors believe is a feasible task for me to accomplish.

Successful results for me would mean having successfully and completely cleaned my data (if needed) and produced summary statistics and visualizations of my data. It would also mean that, of course, the code that I employ in the tools runs successfully and without errors. I will test my project for correctness and efficiency by calculate, by hand, the same calculations performed with my tool of choice. I could also look to run my analysis on two different tools to see how they compare at handling the data being given.

My back-up plan, if this project fails, is to develop a tool that would discuss or solve some economic issue.